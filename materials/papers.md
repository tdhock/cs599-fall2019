## schedule of presentations

Students, please sign up for one slot in first half and one slot in
second half.

First half.

- Aug 29: Toby Dylan Hocking presents [A pruned dynamic programming
  algorithm to recover the best segmentations with 1 to Kmax
  change-points](https://arxiv.org/abs/1004.0887)
- Sep 10 pres 1:
- Sep 10 pres 2:
- Sep 12:
- Sep 17 pres 1:
- Sep 17 pres 2:
- Sep 19:
- Sep 21 pres 1:
- Sep 21 pres 2:
- Sep 23:
- Sep 30 pres 1:
- Sep 30 pres 2:
- Oct 1:
- Oct 8 pres 1:
- Oct 8 pres 2:
- Oct 10:
- Oct 15 pres 1:
- Oct 15 pres 2:
- Oct 17:

Second half.

- Oct 22 pres 1:
- Oct 22 pres 2:
- Oct 24:
- Oct 22 pres 1:
- Oct 22 pres 2:
- Oct 24:
- Oct 29 pres 1:
- Oct 29 pres 2:
- Oct 31:
- Nov 5 pres 1:
- Nov 5 pres 2:
- Nov 7:
- Nov 12 pres 1:
- Nov 12 pres 2:
- Nov 14:
- Nov 19 pres 1:
- Nov 19 pres 2:
- Nov 21:

## suggested papers for student presentations

* [On optimal multiple changepoint algorithms for large data](https://link.springer.com/article/10.1007/s11222-016-9636-3)
* [Complexity analysis of the Lasso regularization path](https://arxiv.org/abs/1205.0079)
* [Minimizing finite sums with the Stochastic Average Gradient](https://arxiv.org/abs/1309.2388)
* [Fast Iterative Shrinkage Thresholding for Linear Inverse Problems](https://epubs.siam.org/doi/abs/10.1137/080716542)
* [Optimizing search engines using clickthrough data](https://dl.acm.org/citation.cfm?id=775067)
* [Group lasso with overlap and graph lasso](http://www.machinelearning.org/archive/icml2009/papers/471.pdf)
* [Block-coordinate Franck-Wolfe Optimization for Structural SVMs](https://arxiv.org/abs/1207.4747)
* [Latent dirichlet allocation](http://www.jmlr.org/papers/v3/blei03a.html)
* [Supervised dictionary learning](http://papers.nips.cc/paper/3448-supervised-dictionary-learning)
* [Convolutional kernel networks](http://papers.nips.cc/paper/5348-convolutional-kernel-networks)
* [Gaussian process kernels for pattern discovery and extrapolation](https://arxiv.org/abs/1302.4245)
* [Character-level convolutional networks for text classification](http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classifica)
* [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)
* [Regularization paths for generalized linear models via coordinate descent](https://www.jstatsoft.org/article/view/v033i01)
* [XGBoost: A Scalable tree boosting system](https://dl.acm.org/citation.cfm?id=2939785)
* [A decision-theoretic generalization of on-line learning and an application to boosting](https://www.sciencedirect.com/science/article/pii/S002200009791504X/pdf?md5=e471323f84c2764746c94ba206a9bc47&pid=1-s2.0-S002200009791504X-main.pdf&_valck=1)
* [Multivariate adaptive regression splines](https://projecteuclid.org/euclid.aos/1176347963)
* [Greedy function approximation: a gradient boosting machine](https://www.jstor.org/stable/2699986?seq=1#page_scan_tab_contents)
* [Least Angle Regression](https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
* [Support-vector networks](https://link.springer.com/article/10.1007/BF00994018)
* [Maximum Margin Interval Trees](http://papers.nips.cc/paper/7080-maximum-margin-interval-trees)
* [Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation](http://papers.nips.cc/paper/3248-direct-importance-estimation-with-model-selection-and-its-application-to-covariate-shift-adaptation)
* [A survey of point-based POMDP solvers](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.711.9951&rep=rep1&type=pdf)

## other options

any paper published at one of the major machine learning conferences
(International Conference on Machine Learning, Neural Information
Processing Systems, International Conference on Artificial
Intelligence and Statistics, International Conference on Learning
Representations, AAAI Conference of the Association for the
Advancement of Artificial Intelligence) or journals (Journal of
Machine Learning Research, Foundations and Trends in Machine Learning,
Neural Computation, Machine Learning, Neural Networks, IEEE
TPAMI). arXiv papers in the
[cs.LG](https://arxiv.org/list/cs.LG/recent) or
[stat.ML](https://arxiv.org/list/stat.ML/recent) categories are
acceptable.
